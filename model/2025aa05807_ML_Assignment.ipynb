{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkNH3hsEpR-6",
        "outputId": "b6707157-3901-484f-e931-d33f779f6294"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    VotingClassifier,\n",
        "    AdaBoostClassifier,\n",
        "    BaggingClassifier\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, roc_curve, auc,\n",
        "    precision_recall_curve, average_precision_score,roc_auc_score,matthews_corrcoef\n",
        ")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"sampathmallagundla\"\n",
        "os.environ['KAGGLE_KEY'] = \"8ca6bbfec3f8bfdc6c0442a31a2e0d98\"\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "import joblib\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# Set style for visualizations\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"husl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# =============================================================================\n",
        "# SECTION 1: DATA LOADING AND PREPARATION\n",
        "# =============================================================================\n",
        "\n",
        "def load_loan_data(filepath=None):\n",
        "\n",
        "    if filepath:\n",
        "        print(f\"Loading data from: {filepath}\")\n",
        "        df = pd.read_csv(filepath)\n",
        "    else:\n",
        "        dataset_slug = 'architsharma01/loan-approval-prediction-dataset'\n",
        "        download_path = 'D:\\\\MyWorkSpace\\\\ML Assignments\\\\data\\\\loan-approval-prediction-dataset'\n",
        "        \n",
        "        api = KaggleApi()\n",
        "        api.authenticate()\n",
        "        # Check if dataset already exists\n",
        "        if not os.path.exists(download_path) or not os.listdir(download_path):\n",
        "            print(\"Dataset not found locally. Downloading from Kaggle...\")\n",
        "            api.dataset_download_files(dataset_slug, path=download_path, unzip=True)\n",
        "            print(\"Download complete.\")\n",
        "        else:\n",
        "            print(\"Dataset already exists locally. Skipping download.\")\n",
        "\n",
        "        \n",
        "        try:\n",
        "            print(f\"Attempting to download from: {'loan_approval_dataset.csv'}\")\n",
        "            df = pd.read_csv('D:\\\\MyWorkSpace\\\\ML Assignments\\\\data\\\\loan-approval-prediction-dataset\\\\loan_approval_dataset.csv')\n",
        "            print(\"Successfully downloaded dataset!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not download dataset: {e}\")\n",
        "            print(\"\\nPlease download the dataset manually from:\")\n",
        "            print(\"https://www.kaggle.com/datasets/architsharma01/loan-approval-prediction-dataset\")\n",
        "            return None\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def explore_data(df):\n",
        "    \"\"\"\n",
        "    Perform exploratory data analysis on the dataset.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EXPLORATORY DATA ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(f\"\\nDataset Shape: {df.shape}\")\n",
        "    print(f\"Total Customers: {len(df):,}\")\n",
        "\n",
        "    print(\"\\nColumn Names:\")\n",
        "    print(df.columns.tolist())\n",
        "\n",
        "    print(\"\\nData Types:\")\n",
        "    print(df.dtypes)\n",
        "\n",
        "    print(\"\\nMissing Values:\")\n",
        "    print(df.isnull().sum()[df.isnull().sum() > 0])\n",
        "\n",
        "    print(\"\\nLoan Status Distribution:\")\n",
        "    print(df[' loan_status'].value_counts())\n",
        "    print(f\"\\nApproved Rate: {df[' loan_status'].value_counts(normalize=True).get('Approved', df[' loan_status'].value_counts(normalize=True).get(1, 0)):.2%}\")\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import le\n",
        "\n",
        "\n",
        "def preprocess_loan_data(df):\n",
        "    \"\"\"\n",
        "    Preprocess the dataset by handling missing values, encoding categorical variables, and scaling features.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"DATA PREPROCESSING\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    \n",
        "\n",
        "    #Strip leading/trailing spaces from column names\n",
        "    df.columns = df.columns.str.strip()\n",
        "\n",
        "    #strip leading/trailing spaces from string columns\n",
        "    for col in df.select_dtypes(include=['object']).columns:\n",
        "        df[col] = df[col].str.strip()\n",
        "\n",
        "\n",
        "    # Handle missing values\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == 'object':\n",
        "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "        else:\n",
        "            df[col].fillna(df[col].median(), inplace=True)\n",
        "\n",
        "    # Encode target variable\n",
        "    #df['loan_status'] = df['loan_status'].map({'Approved': 1, 'Rejected': 0})\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df.drop('loan_status', axis=1)\n",
        "    y = df['loan_status']\n",
        "\n",
        "    # Identify numeric and categorical columns\n",
        "    numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "    categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "    # Create transformers for numeric and categorical features\n",
        "    numeric_transformer = StandardScaler()\n",
        "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_cols),\n",
        "            ('cat', categorical_transformer, categorical_cols)\n",
        "        ])\n",
        "\n",
        "    return X, y, preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_data_splits(X, y,test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Split data into training and testing sets.\n",
        "    \"\"\"\n",
        "    #df processed is with features after encoding and scaling and droping target variable\n",
        "    #X = df_processed.drop('loan_status', axis=1)\n",
        "    #y = df_processed['loan_status']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
        "    )\n",
        "\n",
        "    # Scale features\n",
        "    #scaler = StandardScaler()\n",
        "    #X_train_scaled = scaler.fit_transform(X_train)\n",
        "    #X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    print(f\"\\nTraining set: {len(X_train):,} samples\")\n",
        "    print(f\"Test set: {len(X_test):,} samples\")\n",
        "    print(f\"Features: {X_train.shape[1]}\")\n",
        "    le = LabelEncoder()\n",
        "    y_train_encoded = le.fit_transform(y_train)\n",
        "    y_test_encoded = le.transform(y_test)\n",
        "\n",
        " \n",
        "    #return X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled, scaler\n",
        "    return X_train, X_test, y_train_encoded, y_test_encoded, le"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# SECTION 2: MODEL IMPLEMENTATIONS\n",
        "# ============================================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def train_logistic_regression(X_train, y_train_encoded,preprocessor,le):\n",
        "    \"\"\"\n",
        "    Train and evaluate Logistic Regression model.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"LOGISTIC REGRESSION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Model with regularization tuning\n",
        "    #lr = LogisticRegression(random_state=42, max_iter=1000, C=0.5)\n",
        "    #lr.fit(X_train, y_train)\n",
        "    pipeline = Pipeline([\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"classifier\", LogisticRegression(random_state=42, max_iter=1000, C=0.5))\n",
        "    ])\n",
        "    pipeline.fit(X_train, y_train_encoded)\n",
        "\n",
        "\n",
        "     # Feature importance (coefficients)\n",
        "    if hasattr(X_train, 'columns'):\n",
        "        print(\"\\nTop 5 Feature Coefficients (by absolute value):\")\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'feature': pipeline.named_steps['preprocessor'].get_feature_names_out(),\n",
        "            'coefficient': pipeline.named_steps['classifier'].coef_[0]\n",
        "        }).sort_values('coefficient', key=abs, ascending=False)\n",
        "        print(feature_importance.head())\n",
        "\n",
        "    # Save model to file\n",
        "    joblib.dump({\"pipeline\": pipeline, \"target_encoder\": le}, \"./logistic_regression.pkl\")\n",
        "    return pipeline\n",
        "\n",
        "def test_logistic_regression(lr_model, X_test,y_test):\n",
        "    # Predictions\n",
        "    y_pred = lr_model.predict(X_test)\n",
        "    y_prob = lr_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Evaluation metrics into array and return array.\n",
        "    metrics = [\n",
        "        accuracy_score(y_test, y_pred),\n",
        "        precision_score(y_test, y_pred),\n",
        "        recall_score(y_test, y_pred),\n",
        "        f1_score(y_test, y_pred)\n",
        "    ]\n",
        "    print(f\"\\nAccuracy: {metrics[0]:.4f}\")\n",
        "    print(f\"Precision: {metrics[1]:.4f}\")\n",
        "    print(f\"Recall: {metrics[2]:.4f}\")\n",
        "    print(f\"F1 Score: {metrics[3]:.4f}\")\n",
        "\n",
        "    return y_pred, y_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_decision_tree(X_train, y_train_encoded, preprocessor,le):\n",
        "    \"\"\"\n",
        "    Train and evaluate Decision Tree model with hyperparameter tuning.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"DECISION TREE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Hyperparameter tuning\n",
        "    param_grid = {\n",
        "        'classifier__max_depth': [3, 5, 7, 10],\n",
        "        'classifier__min_samples_split': [2, 5, 10, 20],\n",
        "        'classifier__min_samples_leaf': [1, 2, 4, 8]\n",
        "    }\n",
        "\n",
        "    #dt = DecisionTreeClassifier(random_state=42)\n",
        "    pipeline = Pipeline([\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"classifier\", DecisionTreeClassifier(random_state=42))\n",
        "    ])\n",
        "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train_encoded)\n",
        "\n",
        "    best_dt = grid_search.best_estimator_\n",
        "    print(f\"\\nBest Parameters: {grid_search.best_params_}\")\n",
        "    # Feature importance\n",
        "    if hasattr(X_train, 'columns'):\n",
        "        print(\"\\nTop 5 Feature Importance:\")\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'feature': best_dt.named_steps['preprocessor'].get_feature_names_out(),\n",
        "            'importance': best_dt.named_steps['classifier'].feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "        print(feature_importance.head())\n",
        "    # Save model to file\n",
        "    joblib.dump({\"pipeline\": best_dt, \"target_encoder\": le}, \"./DecisionTree.pkl\")\n",
        "    return best_dt\n",
        "\n",
        "def test_decision_tree(best_dt, X_test, y_test):\n",
        "    # Predictions\n",
        "    y_pred = best_dt.predict(X_test)\n",
        "    y_prob = best_dt.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Evaluation\n",
        "        # Evaluation metrics into array and return array.\n",
        "\n",
        "    print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    return y_pred, y_prob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_knn(X_train, y_train_encoded, preprocessor,le):\n",
        "    \"\"\"\n",
        "    Train and evaluate K-Nearest Neighbors model.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"K-NEAREST NEIGHBORS (KNN)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Find optimal K (odd numbers from 3 to 29 to avoid ties)\n",
        "    k_range = range(3, 30, 2)\n",
        "    cv_scores = []\n",
        "\n",
        "    print(\"\\nSearching for optimal K...\")\n",
        "    for k in k_range:\n",
        "        #knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
        "        pipeline = Pipeline([\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"classifier\", KNeighborsClassifier(n_neighbors=k, weights='distance'))\n",
        "         ])\n",
        "        scores = cross_val_score(pipeline, X_train, y_train_encoded, cv=5, scoring='f1')\n",
        "        cv_scores.append(scores.mean())\n",
        "\n",
        "    best_k = list(k_range)[np.argmax(cv_scores)]\n",
        "    print(f\"Optimal K: {best_k}\")\n",
        "\n",
        "    # Train with best K\n",
        "    #knn = KNeighborsClassifier(n_neighbors=best_k, weights='distance')\n",
        "    #knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"classifier\", KNeighborsClassifier(n_neighbors=best_k, weights='distance'))\n",
        "    ])\n",
        "    pipeline.fit(X_train, y_train_encoded)\n",
        "\n",
        "    # Save model to file\n",
        "    joblib.dump({\"pipeline\": pipeline, \"target_encoder\": le}, \"./KNN.pkl\")\n",
        "\n",
        "    return pipeline, k_range, cv_scores\n",
        "\n",
        "def test_knn(knn, X_test_scaled, y_test):\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = knn.predict(X_test_scaled)\n",
        "    y_prob = knn.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # Evaluation\n",
        "\n",
        "    # Evaluation metrics into array and return array.\n",
        "    print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "\n",
        "    return y_pred, y_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_svm(X_train, y_train_encoded, preprocessor,le):\n",
        "    \"\"\"\n",
        "    Train and evaluate Support Vector Machine model.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SUPPORT VECTOR MACHINE (SVM)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Train with different kernels\n",
        "    kernels = ['linear', 'rbf', 'poly']\n",
        "    results = {}\n",
        "\n",
        "    for kernel in kernels:\n",
        "        print(f\"\\nTraining {kernel} kernel...\")\n",
        "        #svm = SVC(kernel=kernel, probability=True, random_state=42, C=1.0)\n",
        "        #svm.fit(X_train_scaled, y_train)\n",
        "        pipeline = Pipeline([\n",
        "            (\"preprocessor\", preprocessor),\n",
        "            (\"classifier\", SVC(kernel=kernel, probability=True, random_state=42, C=1.0))\n",
        "        ])\n",
        "        pipeline.fit(X_train, y_train_encoded)\n",
        "        results[kernel] = pipeline\n",
        "\n",
        "    # Save model to file\n",
        "    joblib.dump({\"results\": results, \"target_encoder\": le}, \"./SVM.pkl\")\n",
        "    return results\n",
        "\n",
        "def test_svm(svm, X_test, y_test):\n",
        "\n",
        "    kernels = ['linear', 'rbf', 'poly']\n",
        "    results = {}\n",
        "\n",
        "    for kernel in kernels:\n",
        "        print(f\"\\nEvaluating {kernel} kernel...\")\n",
        "            \n",
        "        y_pred = svm[kernel].predict(X_test)\n",
        "        results[kernel] = {\n",
        "                'model': svm[kernel],\n",
        "                'accuracy': accuracy_score(y_test, y_pred),\n",
        "                'f1': f1_score(y_test, y_pred)\n",
        "            }\n",
        "    print(f\"  {kernel.upper()} - Accuracy: {results[kernel]['accuracy']:.4f}, F1: {results[kernel]['f1']:.4f}\")\n",
        "\n",
        "    # Select best kernel\n",
        "    best_kernel = max(results.keys(), key=lambda k: results[k]['f1'])\n",
        "    best_svm = results[best_kernel]['model']\n",
        "\n",
        "    print(f\"\\nBest Kernel: {best_kernel}\")\n",
        "\n",
        "    # Final predictions with best model\n",
        "    y_pred = best_svm.predict(X_test)\n",
        "    y_prob = best_svm.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(f\"\\nFinal Results ({best_kernel}):\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "\n",
        "    return y_pred, y_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_Random_Forest(X_train, y_train_encoded, preprocessor,le):\n",
        "    \"\"\"\n",
        "    Train and evaluate Random Forest model with hyperparameter tuning.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Random Forest ---\")\n",
        "    pipeline = Pipeline([\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"classifier\", RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10, min_samples_split=5, n_jobs=-1))\n",
        "    ])\n",
        "    pipeline.fit(X_train, y_train_encoded)\n",
        "    # Save model to file\n",
        "    joblib.dump({\"pipeline\": pipeline, \"target_encoder\": le}, \"./RandomForest.pkl\")\n",
        "\n",
        "    return pipeline\n",
        "def test_Random_Forest(pipeline, X_test, y_test):\n",
        "    y_pred_rf = pipeline.predict(X_test)\n",
        "    y_prob_rf = pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_test, y_pred_rf):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_test, y_pred_rf):.4f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_test, y_pred_rf):.4f}\")\n",
        "\n",
        "    return y_pred_rf, y_prob_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#XGBoost\n",
        "def train_XGBoost(X_train, y_train_encoded, preprocessor,le):\n",
        "    print(\"\\n--- XGBoost ---\")\n",
        "    pipeline = Pipeline([\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"classifier\", XGBClassifier(random_state=42, n_estimators=100, max_depth=5, learning_rate=0.1, use_label_encoder=False, eval_metric='logloss'))\n",
        "    ])\n",
        "    pipeline.fit(X_train, y_train_encoded)\n",
        "    # Save model to file\n",
        "    joblib.dump({\"pipeline\": pipeline, \"target_encoder\": le}, \"./XGBoost.pkl\")\n",
        "    return pipeline\n",
        "def test_XGBoost(pipeline, X_test, y_test):\n",
        "    y_pred_xgb = pipeline.predict(X_test)\n",
        "    y_prob_xgb = pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_test, y_pred_xgb):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_test, y_pred_xgb):.4f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_test, y_pred_xgb):.4f}\")\n",
        "\n",
        "    return y_pred_xgb, y_prob_xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def train_ensemble_models(X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Train and evaluate Ensemble Learning models.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ENSEMBLE LEARNING\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    ensemble_results = {}\n",
        "\n",
        "    # 1. Random Forest\n",
        "    print(\"\\n--- Random Forest ---\")\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        min_samples_split=5,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred_rf = rf.predict(X_test)\n",
        "    y_prob_rf = rf.predict_proba(X_test)[:, 1]\n",
        "    ensemble_results['Random Forest'] = {\n",
        "        'model': rf,\n",
        "        'y_pred': y_pred_rf,\n",
        "        'y_prob': y_prob_rf,\n",
        "        'accuracy': accuracy_score(y_test, y_pred_rf),\n",
        "        'f1': f1_score(y_test, y_pred_rf)\n",
        "    }\n",
        "    print(f\"Accuracy: {ensemble_results['Random Forest']['accuracy']:.4f}\")\n",
        "    print(f\"F1 Score: {ensemble_results['Random Forest']['f1']:.4f}\")\n",
        "\n",
        "    # 2. Gradient Boosting\n",
        "    print(\"\\n--- Gradient Boosting ---\")\n",
        "    gb = GradientBoostingClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        random_state=42\n",
        "    )\n",
        "    gb.fit(X_train, y_train)\n",
        "    y_pred_gb = gb.predict(X_test)\n",
        "    y_prob_gb = gb.predict_proba(X_test)[:, 1]\n",
        "    ensemble_results['Gradient Boosting'] = {\n",
        "        'model': gb,\n",
        "        'y_pred': y_pred_gb,\n",
        "        'y_prob': y_prob_gb,\n",
        "        'accuracy': accuracy_score(y_test, y_pred_gb),\n",
        "        'f1': f1_score(y_test, y_pred_gb)\n",
        "    }\n",
        "    print(f\"Accuracy: {ensemble_results['Gradient Boosting']['accuracy']:.4f}\")\n",
        "    print(f\"F1 Score: {ensemble_results['Gradient Boosting']['f1']:.4f}\")\n",
        "\n",
        "    # 3. AdaBoost\n",
        "    print(\"\\n--- AdaBoost ---\")\n",
        "    ada = AdaBoostClassifier(n_estimators=100, learning_rate=0.5, random_state=42)\n",
        "    ada.fit(X_train, y_train)\n",
        "    y_pred_ada = ada.predict(X_test)\n",
        "    y_prob_ada = ada.predict_proba(X_test)[:, 1]\n",
        "    ensemble_results['AdaBoost'] = {\n",
        "        'model': ada,\n",
        "        'y_pred': y_pred_ada,\n",
        "        'y_prob': y_prob_ada,\n",
        "        'accuracy': accuracy_score(y_test, y_pred_ada),\n",
        "        'f1': f1_score(y_test, y_pred_ada)\n",
        "    }\n",
        "    print(f\"Accuracy: {ensemble_results['AdaBoost']['accuracy']:.4f}\")\n",
        "    print(f\"F1 Score: {ensemble_results['AdaBoost']['f1']:.4f}\")\n",
        "\n",
        "    # 4. Bagging Classifier\n",
        "    print(\"\\n--- Bagging Classifier ---\")\n",
        "    bagging = BaggingClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
        "    bagging.fit(X_train, y_train)\n",
        "    y_pred_bag = bagging.predict(X_test)\n",
        "    y_prob_bag = bagging.predict_proba(X_test)[:, 1]\n",
        "    ensemble_results['Bagging'] = {\n",
        "        'model': bagging,\n",
        "        'y_pred': y_pred_bag,\n",
        "        'y_prob': y_prob_bag,\n",
        "        'accuracy': accuracy_score(y_test, y_pred_bag),\n",
        "        'f1': f1_score(y_test, y_pred_bag)\n",
        "    }\n",
        "    print(f\"Accuracy: {ensemble_results['Bagging']['accuracy']:.4f}\")\n",
        "    print(f\"F1 Score: {ensemble_results['Bagging']['f1']:.4f}\")\n",
        "\n",
        "    # 5. Voting Classifier\n",
        "    print(\"\\n--- Voting Classifier (Soft Voting) ---\")\n",
        "    voting_clf = VotingClassifier(\n",
        "        estimators=[\n",
        "            ('lr', LogisticRegression(random_state=42, max_iter=1000)),\n",
        "            ('rf', RandomForestClassifier(n_estimators=50, max_depth=8, random_state=42)),\n",
        "            ('gb', GradientBoostingClassifier(n_estimators=50, max_depth=4, random_state=42))\n",
        "        ],\n",
        "        voting='soft'\n",
        "    )\n",
        "    voting_clf.fit(X_train, y_train)\n",
        "    y_pred_vote = voting_clf.predict(X_test)\n",
        "    y_prob_vote = voting_clf.predict_proba(X_test)[:, 1]\n",
        "    ensemble_results['Voting Classifier'] = {\n",
        "        'model': voting_clf,\n",
        "        'y_pred': y_pred_vote,\n",
        "        'y_prob': y_prob_vote,\n",
        "        'accuracy': accuracy_score(y_test, y_pred_vote),\n",
        "        'f1': f1_score(y_test, y_pred_vote)\n",
        "    }\n",
        "    print(f\"Accuracy: {ensemble_results['Voting Classifier']['accuracy']:.4f}\")\n",
        "    print(f\"F1 Score: {ensemble_results['Voting Classifier']['f1']:.4f}\")\n",
        "\n",
        "    # 6 XGBoost\n",
        "    print(\"\\n--- XGBoost ---\")\n",
        "    try:\n",
        "        xgb = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "        xgb.fit(X_train, y_train)\n",
        "        y_pred_xgb = xgb.predict(X_test)\n",
        "        y_prob_xgb = xgb.predict_proba(X_test)[:, 1]\n",
        "        ensemble_results['XGBoost'] = {\n",
        "            'model': xgb,\n",
        "            'y_pred': y_pred_xgb,\n",
        "            'y_prob': y_prob_xgb,\n",
        "            'accuracy': accuracy_score(y_test, y_pred_xgb),\n",
        "            'f1': f1_score(y_test, y_pred_xgb)\n",
        "        }\n",
        "        print(f\"Accuracy: {ensemble_results['XGBoost']['accuracy']:.4f}\")\n",
        "        print(f\"F1 Score: {ensemble_results['XGBoost']['f1']:.4f}\")\n",
        "    except ImportError:\n",
        "        print(\"XGBoost is not installed. Skipping XGBoost model.\")\n",
        "\n",
        "    return ensemble_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Generate code for Naive Bays Classifier\n",
        "def train_Naive_Bayes_models(X_train, y_train_encoded,preprocessor,le):\n",
        "\n",
        "    \"\"\"\n",
        "    Train and evaluate Ensemble Learning models.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ENSEMBLE LEARNING\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    naive_bayes_results = {}\n",
        "\n",
        "    # 1. Gaussian Naive Bayes\n",
        "    from sklearn.naive_bayes import GaussianNB\n",
        "    print(\"\\n--- Gaussian Naive Bayes ---\")\n",
        "    #gnb = GaussianNB()\n",
        "    #gnb.fit(X_train, y_train_encoded)\n",
        "    pipeline = Pipeline([\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"classifier\", GaussianNB())\n",
        "    ])\n",
        "    pipeline.fit(X_train, y_train_encoded)\n",
        "\n",
        "    # Save model to file\n",
        "    joblib.dump({\"pipeline\": pipeline, \"target_encoder\": le}, \"./NaiveBayes.pkl\")\n",
        "    return pipeline\n",
        "\n",
        "def test_Naive_Bayes_models(pipeline, X_test, y_test):\n",
        "    y_pred_gnb = pipeline.predict(X_test)\n",
        "    y_prob_gnb = pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_gnb):.4f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_test, y_pred_gnb, zero_division=0):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_test, y_pred_gnb, zero_division=0):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_test, y_pred_gnb, zero_division=0):.4f}\")\n",
        "    \n",
        "    return y_pred_gnb,y_prob_gnb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# =============================================================================\n",
        "# SECTION 3: EVALUATION & VISUALIZATION\n",
        "# ============================================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def plot_confusion_matrices(y_test, predictions_dict, save_path='confusion_matrices.png'):\n",
        "    \"\"\"Plot confusion matrices for all models.\"\"\"\n",
        "    n_models = len(predictions_dict)\n",
        "    n_cols = 3\n",
        "    n_rows = (n_models + n_cols - 1) // n_cols\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, 4*n_rows))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for idx, (name, y_pred) in enumerate(predictions_dict.items()):\n",
        "        if idx < len(axes):\n",
        "            cm = confusion_matrix(y_test, y_pred)\n",
        "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
        "                       xticklabels=['No Churn', 'Churn'],\n",
        "                       yticklabels=['No Churn', 'Churn'])\n",
        "            axes[idx].set_title(f'{name}', fontsize=11, fontweight='bold')\n",
        "            axes[idx].set_xlabel('Predicted')\n",
        "            axes[idx].set_ylabel('Actual')\n",
        "\n",
        "    for idx in range(n_models, len(axes)):\n",
        "        axes[idx].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    #plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    #plt.close()\n",
        "    plt.show()\n",
        "    #print(f\"Saved: {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def plot_roc_curves(y_test, probabilities_dict, save_path='roc_curves.png'):\n",
        "    \"\"\"Plot ROC curves for all models.\"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, len(probabilities_dict)))\n",
        "\n",
        "    for (name, y_prob), color in zip(probabilities_dict.items(), colors):\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, color=color, lw=2, label=f'{name} (AUC = {roc_auc:.3f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate', fontsize=12)\n",
        "    plt.ylabel('True Positive Rate', fontsize=12)\n",
        "    plt.title('ROC Curves Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.legend(loc='lower right', fontsize=9)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    #plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    #plt.close()\n",
        "    #print(f\"Saved: {save_path}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def plot_precision_recall_curves(y_test, probabilities_dict, save_path='pr_curves.png'):\n",
        "    \"\"\"Plot Precision-Recall curves for all models.\"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, len(probabilities_dict)))\n",
        "\n",
        "    for (name, y_prob), color in zip(probabilities_dict.items(), colors):\n",
        "        precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "        avg_precision = average_precision_score(y_test, y_prob)\n",
        "        plt.plot(recall, precision, color=color, lw=2,\n",
        "                label=f'{name} (AP = {avg_precision:.3f})')\n",
        "\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('Recall', fontsize=12)\n",
        "    plt.ylabel('Precision', fontsize=12)\n",
        "    plt.title('Precision-Recall Curves Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.legend(loc='lower left', fontsize=9)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    #plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    #plt.close()\n",
        "    #print(f\"Saved: {save_path}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def plot_model_comparison(metrics_dict, save_path='model_comparison.png'):\n",
        "    \"\"\"Create a bar chart comparing all models across metrics.\"\"\"\n",
        "    metrics_df = pd.DataFrame(metrics_dict).T\n",
        "\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(16, 5))\n",
        "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "    colors = ['#3498db', '#2ecc71', '#e74c3c', '#9b59b6']\n",
        "\n",
        "    for idx, (metric, color) in enumerate(zip(metrics, colors)):\n",
        "        values = metrics_df[metric].sort_values(ascending=True)\n",
        "        axes[idx].barh(values.index, values.values, color=color, alpha=0.8)\n",
        "        axes[idx].set_xlabel(metric, fontsize=11)\n",
        "        axes[idx].set_xlim([0.4, 1.0])\n",
        "        axes[idx].set_title(metric, fontsize=12, fontweight='bold')\n",
        "        for i, v in enumerate(values.values):\n",
        "            axes[idx].text(v + 0.01, i, f'{v:.3f}', va='center', fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    #plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    #plt.close()\n",
        "    #print(f\"Saved: {save_path}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def plot_knn_optimization(k_range, cv_scores, save_path='knn_optimization.png'):\n",
        "    \"\"\"Plot KNN optimization curve showing optimal K value.\"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    k_list = list(k_range)\n",
        "    plt.plot(k_list, cv_scores, 'b-o', linewidth=2, markersize=6)\n",
        "    plt.fill_between(k_list, cv_scores, alpha=0.2)\n",
        "\n",
        "    best_k = k_list[np.argmax(cv_scores)]\n",
        "    best_score = max(cv_scores)\n",
        "    plt.axvline(x=best_k, color='r', linestyle='--', label=f'Optimal K = {best_k}')\n",
        "    plt.scatter([best_k], [best_score], color='red', s=150, zorder=5, marker='*')\n",
        "\n",
        "    plt.xlabel('Number of Neighbors (K)', fontsize=12)\n",
        "    plt.ylabel('Cross-Validation F1 Score', fontsize=12)\n",
        "    plt.title('KNN Hyperparameter Optimization', fontsize=14, fontweight='bold')\n",
        "    plt.legend(fontsize=11)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    #plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    #plt.close()\n",
        "    #print(f\"Saved: {save_path}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_feature_importance(model, feature_names, title, save_path):\n",
        "    \"\"\"Plot feature importance for tree-based models.\"\"\"\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        importance = model.feature_importances_\n",
        "    elif hasattr(model, 'coef_'):\n",
        "        importance = np.abs(model.coef_[0])\n",
        "    else:\n",
        "        return\n",
        "\n",
        "    feature_imp = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'importance': importance\n",
        "    }).sort_values('importance', ascending=True).tail(10)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(feature_imp['feature'], feature_imp['importance'], color='#3498db', alpha=0.8)\n",
        "    plt.xlabel('Importance', fontsize=12)\n",
        "    plt.title(f'{title} - Top 10 Features', fontsize=14, fontweight='bold')\n",
        "    plt.grid(True, alpha=0.3, axis='x')\n",
        "    plt.tight_layout()\n",
        "    #plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    #plt.close()\n",
        "    #print(f\"Saved: {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def create_summary_table(metrics_dict):\n",
        "    \"\"\"Create a summary table of all model metrics.\"\"\"\n",
        "    df = pd.DataFrame(metrics_dict).T\n",
        "    df = df.round(4)\n",
        "    df.index.name = 'Model'\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# SECTION 4: MAIN EXECUTION\n",
        "# ============================================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "Loan Approval Prediction - Model Comparison\n",
            "======================================================================\n",
            "\n",
            "[1] LOADING DATA...\n",
            "Dataset already exists locally. Skipping download.\n",
            "Attempting to download from: loan_approval_dataset.csv\n",
            "Successfully downloaded dataset!\n",
            "\n",
            "============================================================\n",
            "EXPLORATORY DATA ANALYSIS\n",
            "============================================================\n",
            "\n",
            "Dataset Shape: (4269, 13)\n",
            "Total Customers: 4,269\n",
            "\n",
            "Column Names:\n",
            "['loan_id', ' no_of_dependents', ' education', ' self_employed', ' income_annum', ' loan_amount', ' loan_term', ' cibil_score', ' residential_assets_value', ' commercial_assets_value', ' luxury_assets_value', ' bank_asset_value', ' loan_status']\n",
            "\n",
            "Data Types:\n",
            "loan_id                       int64\n",
            " no_of_dependents             int64\n",
            " education                   object\n",
            " self_employed               object\n",
            " income_annum                 int64\n",
            " loan_amount                  int64\n",
            " loan_term                    int64\n",
            " cibil_score                  int64\n",
            " residential_assets_value     int64\n",
            " commercial_assets_value      int64\n",
            " luxury_assets_value          int64\n",
            " bank_asset_value             int64\n",
            " loan_status                 object\n",
            "dtype: object\n",
            "\n",
            "Missing Values:\n",
            "Series([], dtype: int64)\n",
            "\n",
            "Loan Status Distribution:\n",
            " loan_status\n",
            "Approved    2656\n",
            "Rejected    1613\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Approved Rate: 37.78%\n",
            "\n",
            "============================================================\n",
            "DATA PREPROCESSING\n",
            "============================================================\n",
            "\n",
            "Training set: 3,415 samples\n",
            "Test set: 854 samples\n",
            "Features: 12\n",
            "\n",
            "[2] TRAINING MODELS...\n",
            "\n",
            "============================================================\n",
            "LOGISTIC REGRESSION\n",
            "============================================================\n",
            "\n",
            "Top 5 Feature Coefficients (by absolute value):\n",
            "                    feature  coefficient\n",
            "5          num__cibil_score    -3.995462\n",
            "2         num__income_annum     1.465000\n",
            "3          num__loan_amount    -1.142879\n",
            "4            num__loan_term     0.823119\n",
            "8  num__luxury_assets_value    -0.271589\n",
            "\n",
            "Accuracy: 0.9239\n",
            "Precision: 0.9216\n",
            "Recall: 0.8731\n",
            "F1 Score: 0.8967\n",
            "\n",
            "============================================================\n",
            "DECISION TREE\n",
            "============================================================\n",
            "\n",
            "Best Parameters: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 2}\n",
            "\n",
            "Top 5 Feature Importance:\n",
            "                    feature  importance\n",
            "5          num__cibil_score    0.846427\n",
            "4            num__loan_term    0.085607\n",
            "3          num__loan_amount    0.029169\n",
            "2         num__income_annum    0.018430\n",
            "8  num__luxury_assets_value    0.009341\n",
            "\n",
            "Accuracy: 0.9789\n",
            "Precision: 0.9872\n",
            "Recall: 0.9567\n",
            "F1 Score: 0.9717\n",
            "\n",
            "============================================================\n",
            "K-NEAREST NEIGHBORS (KNN)\n",
            "============================================================\n",
            "\n",
            "Searching for optimal K...\n",
            "Optimal K: 29\n",
            "\n",
            "Accuracy: 0.9286\n",
            "Precision: 0.9172\n",
            "Recall: 0.8916\n",
            "F1 Score: 0.9042\n",
            "\n",
            "--- Random Forest ---\n",
            "\n",
            "Accuracy: 0.9754\n",
            "Precision: 0.9689\n",
            "Recall: 0.9659\n",
            "F1 Score: 0.9674\n",
            "\n",
            "--- XGBoost ---\n",
            "\n",
            "Accuracy: 0.9824\n",
            "Precision: 0.9873\n",
            "Recall: 0.9659\n",
            "F1 Score: 0.9765\n",
            "\n",
            "============================================================\n",
            "ENSEMBLE LEARNING\n",
            "============================================================\n",
            "\n",
            "--- Gaussian Naive Bayes ---\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './model/NaiveBayes.pkl'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 198\u001b[39m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    189\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m'\u001b[39m: model,\n\u001b[32m    190\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mpredictions\u001b[39m\u001b[33m'\u001b[39m: all_predictions,\n\u001b[32m   (...)\u001b[39m\u001b[32m    193\u001b[39m         \u001b[33m'\u001b[39m\u001b[33msummary\u001b[39m\u001b[33m'\u001b[39m: summary_df\n\u001b[32m    194\u001b[39m     }\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     results = \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 128\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(data_path)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"ensemble_results = train_ensemble_models(X_train, y_train, X_test, y_test)\u001b[39;00m\n\u001b[32m    117\u001b[39m \n\u001b[32m    118\u001b[39m \u001b[33;03mfor name, results in ensemble_results.items():\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \u001b[33;03m        'F1 Score': f1_score(y_test, results['y_pred'])\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m    }\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# Naive Bayes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m pipeline = \u001b[43mtrain_Naive_Bayes_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m y_pred_gnb, y_prob_gnb = test_Naive_Bayes_models(pipeline, X_test, y_test_encoded)\n\u001b[32m    130\u001b[39m all_predictions[\u001b[33m'\u001b[39m\u001b[33mNaive Bayes\u001b[39m\u001b[33m'\u001b[39m] = y_pred_gnb\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mtrain_Naive_Bayes_models\u001b[39m\u001b[34m(X_train, y_train_encoded, preprocessor, le)\u001b[39m\n\u001b[32m     22\u001b[39m pipeline.fit(X_train, y_train_encoded)\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Save model to file\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtarget_encoder\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mle\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./model/NaiveBayes.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\numpy_pickle.py:599\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(value, filename, compress, protocol)\u001b[39m\n\u001b[32m    597\u001b[39m         NumpyPickler(f, protocol=protocol).dump(value)\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    600\u001b[39m         NumpyPickler(f, protocol=protocol).dump(value)\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './model/NaiveBayes.pkl'"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from xml.parsers.expat import model\n",
        "import joblib\n",
        "\n",
        "\n",
        "def main(data_path=None):\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"Loan Approval Prediction - Model Comparison\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # 1. Load data\n",
        "    print(\"\\n[1] LOADING DATA...\")\n",
        "    df = load_loan_data(data_path)\n",
        "\n",
        "    if df is None:\n",
        "        print(\"\\nERROR: Could not load dataset. Please provide a valid path.\")\n",
        "        return None\n",
        "\n",
        "    # 2. Explore data\n",
        "    df = explore_data(df)\n",
        "    # 3. Preprocess data\n",
        "    X, y, preprocessor = preprocess_loan_data(df)\n",
        "    X_train, X_test, y_train_encoded, y_test_encoded, le = prepare_data_splits(X, y)\n",
        "\n",
        "    feature_names = X_train.columns\n",
        "    \n",
        "    # Store all predictions and probabilities\n",
        "    all_predictions = {}\n",
        "    all_probabilities = {}\n",
        "    all_metrics = {}\n",
        "\n",
        "    # 4. Train models\n",
        "    print(\"\\n[2] TRAINING MODELS...\")\n",
        "\n",
        "    # Logistic Regression\n",
        "    pipeline = train_logistic_regression(X_train, y_train_encoded,preprocessor,le)\n",
        "    lr_pred, lr_prob = test_logistic_regression(pipeline, X_test,y_test_encoded)\n",
        "    all_predictions['Logistic Regression'] = lr_pred\n",
        "    all_probabilities['Logistic Regression'] = lr_prob\n",
        "    all_metrics['Logistic Regression'] = {\n",
        "        'Accuracy': accuracy_score(y_test_encoded, lr_pred),\n",
        "        'AUC Score': roc_auc_score(y_test_encoded, lr_prob),\n",
        "        'Precision': precision_score(y_test_encoded, lr_pred),\n",
        "        'Recall': recall_score(y_test_encoded, lr_pred),\n",
        "        'F1 Score': f1_score(y_test_encoded, lr_pred),\n",
        "        'MCC Score': matthews_corrcoef(y_test_encoded, lr_pred)\n",
        "    }\n",
        "\n",
        "    # Decision Tree\n",
        "    dt_model = train_decision_tree(X_train, y_train_encoded,preprocessor,le)\n",
        "    dt_pred, dt_prob = test_decision_tree(dt_model, X_test,y_test_encoded)\n",
        "    all_predictions['Decision Tree'] = dt_pred\n",
        "    all_probabilities['Decision Tree'] = dt_prob\n",
        "    all_metrics['Decision Tree'] = {\n",
        "        'Accuracy': accuracy_score(y_test_encoded, dt_pred),\n",
        "        'AUC Score': roc_auc_score(y_test_encoded, dt_prob),\n",
        "        'Precision': precision_score(y_test_encoded, dt_pred),\n",
        "        'Recall': recall_score(y_test_encoded, dt_pred),\n",
        "        'F1 Score': f1_score(y_test_encoded, dt_pred),\n",
        "        'MCC Score': matthews_corrcoef(y_test_encoded, dt_pred)\n",
        "    }\n",
        "\n",
        "    # KNN\n",
        "    pipeline, k_range, cv_scores = train_knn(X_train, y_train_encoded,preprocessor,le)\n",
        "    knn_pred, knn_prob = test_knn(pipeline, X_test, y_test_encoded)\n",
        "    all_predictions['KNN'] = knn_pred\n",
        "    all_probabilities['KNN'] = knn_prob\n",
        "    all_metrics['KNN'] = {\n",
        "        'Accuracy': accuracy_score(y_test_encoded, knn_pred),\n",
        "        'AUC Score': roc_auc_score(y_test_encoded, knn_prob),\n",
        "        'Precision': precision_score(y_test_encoded, knn_pred),\n",
        "        'Recall': recall_score(y_test_encoded, knn_pred),\n",
        "        'F1 Score': f1_score(y_test_encoded, knn_pred),\n",
        "        'MCC Score': matthews_corrcoef(y_test_encoded, knn_pred)\n",
        "    }\n",
        "    # SVM\n",
        "    \"\"\"svm_model = train_svm(X_train, y_train_encoded,preprocessor,le)\n",
        "    svm_pred, svm_prob = test_svm(svm_model, X_test, y_test_encoded)\n",
        "    all_predictions['SVM'] = svm_pred\n",
        "    all_probabilities['SVM'] = svm_prob\n",
        "    all_metrics['SVM'] = {\n",
        "        'Accuracy': accuracy_score(y_test_encoded, svm_pred),\n",
        "        'Precision': precision_score(y_test_encoded, svm_pred),\n",
        "        'Recall': recall_score(y_test_encoded, svm_pred),\n",
        "        'F1 Score': f1_score(y_test_encoded, svm_pred)\n",
        "    }\"\"\"\n",
        "\n",
        "    #Random Forest\n",
        "    pipeline = train_Random_Forest(X_train, y_train_encoded,preprocessor,le)\n",
        "    rf_pred, rf_prob = test_Random_Forest(pipeline, X_test, y_test_encoded)\n",
        "    all_predictions['Random Forest'] = rf_pred\n",
        "    all_probabilities['Random Forest'] = rf_prob\n",
        "    all_metrics['Random Forest'] = {\n",
        "        'Accuracy': accuracy_score(y_test_encoded, rf_pred),\n",
        "        'AUC Score': roc_auc_score(y_test_encoded, rf_prob),\n",
        "        'Precision': precision_score(y_test_encoded, rf_pred),\n",
        "        'Recall': recall_score(y_test_encoded, rf_pred),\n",
        "        'F1 Score': f1_score(y_test_encoded, rf_pred),\n",
        "        'MCC Score': matthews_corrcoef(y_test_encoded, rf_pred)\n",
        "    }\n",
        "\n",
        "    #XGBoost\n",
        "    pipeline = train_XGBoost(X_train, y_train_encoded,preprocessor,le)\n",
        "    xgb_pred, xgb_prob = test_XGBoost(pipeline, X_test, y_test_encoded)\n",
        "    all_predictions['XGBoost'] = xgb_pred\n",
        "    all_probabilities['XGBoost'] = xgb_prob\n",
        "    all_metrics['XGBoost'] = {\n",
        "        'Accuracy': accuracy_score(y_test_encoded, xgb_pred),\n",
        "        'AUC Score': roc_auc_score(y_test_encoded, xgb_prob),\n",
        "        'Precision': precision_score(y_test_encoded, xgb_pred),\n",
        "        'Recall': recall_score(y_test_encoded, xgb_pred),\n",
        "        'F1 Score': f1_score(y_test_encoded, xgb_pred),\n",
        "        'MCC Score': matthews_corrcoef(y_test_encoded, xgb_pred)    \n",
        "    }\n",
        "    # Ensemble Methods\n",
        "    \"\"\"ensemble_results = train_ensemble_models(X_train, y_train, X_test, y_test)\n",
        "\n",
        "    for name, results in ensemble_results.items():\n",
        "        all_predictions[name] = results['y_pred']\n",
        "        all_probabilities[name] = results['y_prob']\n",
        "        all_metrics[name] = {\n",
        "            'Accuracy': accuracy_score(y_test, results['y_pred']),\n",
        "            'Precision': precision_score(y_test, results['y_pred']),\n",
        "            'Recall': recall_score(y_test, results['y_pred']),\n",
        "            'F1 Score': f1_score(y_test, results['y_pred'])\n",
        "        }\"\"\"\n",
        "    # Naive Bayes\n",
        "    pipeline = train_Naive_Bayes_models(X_train, y_train_encoded,preprocessor,le)\n",
        "    y_pred_gnb, y_prob_gnb = test_Naive_Bayes_models(pipeline, X_test, y_test_encoded)\n",
        "    all_predictions['Naive Bayes'] = y_pred_gnb\n",
        "    all_probabilities['Naive Bayes'] = y_prob_gnb\n",
        "    all_metrics['Naive Bayes'] = {\n",
        "        'Accuracy': accuracy_score(y_test_encoded, y_pred_gnb),\n",
        "        'AUC Score': roc_auc_score(y_test_encoded, y_prob_gnb),\n",
        "        'Precision': precision_score(y_test_encoded, y_pred_gnb),\n",
        "        'Recall': recall_score(y_test_encoded, y_pred_gnb),\n",
        "        'F1 Score': f1_score(y_test_encoded, y_pred_gnb),\n",
        "        'MCC Score': matthews_corrcoef(y_test_encoded, y_pred_gnb)\n",
        "    }\n",
        "\n",
        "    # 5. Generate visualizations\n",
        "    print(\"\\n[3] GENERATING VISUALIZATIONS...\")\n",
        "\n",
        "    plot_confusion_matrices(y_test_encoded, all_predictions)\n",
        "    plot_roc_curves(y_test_encoded, all_probabilities)\n",
        "    plot_precision_recall_curves(y_test_encoded, all_probabilities)\n",
        "    plot_model_comparison(all_metrics)\n",
        "    plot_knn_optimization(k_range, cv_scores)\n",
        "    \"\"\"plot_feature_importance(ensemble_results['Random Forest']['model'], feature_names,\n",
        "                           'Random Forest', 'rf_feature_importance.png')\n",
        "    plot_feature_importance(ensemble_results['Gradient Boosting']['model'], feature_names,\n",
        "                           'Gradient Boosting', 'gb_feature_importance.png')\"\"\"\n",
        "\n",
        "    # 6. Create summary\n",
        "    print(\"\\n[4] FINAL SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    summary_df = create_summary_table(all_metrics)\n",
        "    print(\"\\nModel Performance Summary:\")\n",
        "    print(summary_df.to_string())\n",
        "\n",
        "    # Best model\n",
        "    best_model = summary_df['F1 Score'].idxmax()\n",
        "    print(f\"\\n Best Performing Model (by F1 Score): {best_model}\")\n",
        "    print(f\"   F1 Score: {summary_df.loc[best_model, 'F1 Score']:.4f}\")\n",
        "    print(f\"   Accuracy: {summary_df.loc[best_model, 'Accuracy']:.4f}\")\n",
        "\n",
        "    # Save summary to CSV\n",
        "    summary_df.to_csv('model_comparison_summary.csv')\n",
        "    print(\"\\nSummary saved to: model_comparison_summary.csv\")\n",
        "    \n",
        "    #move all models into a dictionary for saving\n",
        "    \"\"\"model = {\n",
        "        'Logistic Regression': lr_model,\n",
        "        'Decision Tree': dt_model,\n",
        "        'KNN': knn_model,\n",
        "        'Naive Bayes': gnb,\n",
        "        'Random Forest': rf_model,\n",
        "        'XGBoost': xgb_model,\n",
        "        'Ensemble Models': ensemble_results,\n",
        "        'SVM'  : svm_model\n",
        "    }\"\"\"\n",
        "    \n",
        "\n",
        "    # Save model to file\n",
        "    #joblib.dump(model, \"loan_approval_model.pkl\")\n",
        "\n",
        "    return {\n",
        "        'models': model,\n",
        "        'predictions': all_predictions,\n",
        "        'probabilities': all_probabilities,\n",
        "        'metrics': all_metrics,\n",
        "        'summary': summary_df\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  \n",
        "    results = main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
